#!/usr/bin/env bash
# ai-debug-parallel-tests - Execute tests in parallel for maximum speed
# Part of AI Debug Context V3 - Shell-first architecture
# Compatible with bash 4+, zsh 5+, fish 3+

set -euo pipefail

# Script metadata
readonly SCRIPT_NAME="ai-debug-parallel-tests"
readonly VERSION="3.0.0"

# Default configuration
readonly DEFAULT_CONCURRENCY="auto"
readonly MAX_CONCURRENCY=8
readonly MIN_CONCURRENCY=2

# Color output (if terminal supports it)
if [[ -t 1 ]] && command -v tput >/dev/null 2>&1; then
    readonly RED=$(tput setaf 1)
    readonly GREEN=$(tput setaf 2)
    readonly YELLOW=$(tput setaf 3)
    readonly BLUE=$(tput setaf 4)
    readonly BOLD=$(tput bold)
    readonly RESET=$(tput sgr0)
else
    readonly RED=""
    readonly GREEN=""
    readonly YELLOW=""
    readonly BLUE=""
    readonly BOLD=""
    readonly RESET=""
fi

# Logging functions
log_info() {
    echo "${BLUE}[INFO]${RESET} $*" >&2
}

log_warn() {
    echo "${YELLOW}[WARN]${RESET} $*" >&2
}

log_error() {
    echo "${RED}[ERROR]${RESET} $*" >&2
}

log_success() {
    echo "${GREEN}[SUCCESS]${RESET} $*" >&2
}

# Show usage information
show_usage() {
    cat << EOF
${BOLD}$SCRIPT_NAME${RESET} - Execute tests in parallel for maximum speed

${BOLD}USAGE:${RESET}
    $SCRIPT_NAME [OPTIONS] [TEST_FILES...]
    echo "test1.spec.ts test2.spec.ts" | $SCRIPT_NAME [OPTIONS]

${BOLD}OPTIONS:${RESET}
    -c, --concurrency NUM   Number of parallel processes (default: auto)
    -o, --output DIR        Output directory for results (default: ./test-results)
    -t, --timeout SEC       Timeout per test chunk in seconds (default: 300)
    -v, --verbose           Enable verbose output
    -d, --dry-run          Show what would be executed without running
    -h, --help             Show this help message
    --version              Show version information

${BOLD}EXAMPLES:${RESET}
    $SCRIPT_NAME test1.spec.ts test2.spec.ts    # Run specific tests in parallel
    echo "*.spec.ts" | $SCRIPT_NAME             # Run tests from stdin
    $SCRIPT_NAME --concurrency 4                # Use 4 parallel processes
    $SCRIPT_NAME --dry-run                       # Show execution plan

${BOLD}DESCRIPTION:${RESET}
    Splits test files into chunks and executes them in parallel processes
    for 5-10x speed improvement over serial execution. Automatically detects
    optimal concurrency based on CPU cores and available memory.

${BOLD}PERFORMANCE:${RESET}
    - Automatic concurrency detection (CPU cores / 2, min 2, max 8)
    - Cross-platform CPU detection (Linux, macOS, Windows/WSL)
    - Intelligent chunk sizing based on test file count
    - Aggregated results with detailed timing information

EOF
}

# Show version information
show_version() {
    echo "$SCRIPT_NAME version $VERSION"
}

# Detect optimal concurrency based on system resources
get_optimal_concurrency() {
    local cpu_count
    
    # Cross-platform CPU detection
    if command -v nproc >/dev/null 2>&1; then
        # Linux
        cpu_count=$(nproc)
    elif [[ -f /proc/cpuinfo ]]; then
        # Linux fallback
        cpu_count=$(grep -c ^processor /proc/cpuinfo)
    elif command -v sysctl >/dev/null 2>&1; then
        # macOS/BSD
        cpu_count=$(sysctl -n hw.ncpu 2>/dev/null || echo "4")
    elif command -v wmic >/dev/null 2>&1; then
        # Windows
        cpu_count=$(wmic cpu get NumberOfCores /value | grep -o '[0-9]*' | head -1)
    else
        # Safe fallback
        cpu_count=4
    fi
    
    # Calculate optimal concurrency
    # Use half of available cores for safety, with min/max bounds
    local concurrency=$((cpu_count / 2))
    [[ $concurrency -lt $MIN_CONCURRENCY ]] && concurrency=$MIN_CONCURRENCY
    [[ $concurrency -gt $MAX_CONCURRENCY ]] && concurrency=$MAX_CONCURRENCY
    
    echo "$concurrency"
}

# Validate Jest is available
check_jest_available() {
    if ! command -v npx >/dev/null 2>&1; then
        log_error "npx command not found"
        log_error "Please install Node.js and npm"
        return 1
    fi
    
    if ! npx jest --version >/dev/null 2>&1; then
        log_error "Jest not found"
        log_error "Please install Jest: npm install --save-dev jest"
        return 1
    fi
}

# Split test files into chunks for parallel execution
create_test_chunks() {
    local test_files="$1"
    local chunk_count="$2"
    local output_dir="$3"
    
    if [[ -z "$test_files" ]]; then
        log_warn "No test files to chunk"
        return 0
    fi
    
    local file_count
    file_count=$(echo "$test_files" | wc -l)
    
    if [[ $file_count -eq 0 ]]; then
        log_warn "No test files provided"
        return 0
    fi
    
    log_info "Splitting $file_count test files into $chunk_count chunks"
    
    # Calculate chunk size (round up)
    local chunk_size=$(( (file_count + chunk_count - 1) / chunk_count ))
    
    # Create output directory
    mkdir -p "$output_dir"
    
    # Clean up any existing chunk files
    rm -f "$output_dir"/chunk_*.txt
    
    # Split test files into chunks
    echo "$test_files" | split -l "$chunk_size" - "$output_dir/chunk_"
    
    # Rename chunk files to have .txt extension for clarity
    local chunk_id=0
    for chunk_file in "$output_dir"/chunk_*; do
        if [[ -f "$chunk_file" && ! "$chunk_file" =~ \.txt$ ]]; then
            mv "$chunk_file" "${chunk_file}_${chunk_id}.txt"
            ((chunk_id++))
        fi
    done
    
    # Return number of chunks created
    find "$output_dir" -name "chunk_*.txt" | wc -l
}

# Execute a single test chunk
run_test_chunk() {
    local chunk_file="$1"
    local chunk_id="$2"
    local output_dir="$3"
    local timeout="$4"
    local verbose="$5"
    
    if [[ ! -f "$chunk_file" ]]; then
        log_error "Chunk file not found: $chunk_file"
        return 1
    fi
    
    local chunk_output="$output_dir/results_chunk_$chunk_id.json"
    local chunk_log="$output_dir/log_chunk_$chunk_id.txt"
    local start_time end_time duration
    
    start_time=$(date +%s)
    
    if [[ "$verbose" == "true" ]]; then
        log_info "Starting chunk $chunk_id ($(wc -l < "$chunk_file") tests)"
    fi
    
    # Build Jest command with chunk-specific test files
    local jest_args=(
        --json
        --outputFile="$chunk_output"
        --passWithNoTests
        --silent
        --maxWorkers=1  # Each chunk runs in its own process
    )
    
    # Add test files from chunk as arguments
    local test_file_args=()
    while IFS= read -r test_file; do
        if [[ -n "$test_file" && -f "$test_file" ]]; then
            test_file_args+=("$test_file")
        fi
    done < "$chunk_file"
    
    if [[ ${#test_file_args[@]} -eq 0 ]]; then
        log_warn "No valid test files in chunk $chunk_id"
        echo '{"numTotalTests":0,"numPassedTests":0,"numFailedTests":0,"testResults":[]}' > "$chunk_output"
        return 0
    fi
    
    # Execute Jest with timeout
    local exit_code=0
    if command -v timeout >/dev/null 2>&1; then
        # Linux/macOS with coreutils
        timeout "$timeout" npx jest "${jest_args[@]}" "${test_file_args[@]}" >"$chunk_log" 2>&1 || exit_code=$?
    elif command -v gtimeout >/dev/null 2>&1; then
        # macOS with GNU coreutils via Homebrew
        gtimeout "$timeout" npx jest "${jest_args[@]}" "${test_file_args[@]}" >"$chunk_log" 2>&1 || exit_code=$?
    else
        # Fallback without timeout
        npx jest "${jest_args[@]}" "${test_file_args[@]}" >"$chunk_log" 2>&1 || exit_code=$?
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    
    # Log completion status
    if [[ $exit_code -eq 0 ]]; then
        if [[ "$verbose" == "true" ]]; then
            log_success "Chunk $chunk_id completed in ${duration}s"
        fi
    else
        log_error "Chunk $chunk_id failed (exit code: $exit_code, duration: ${duration}s)"
        
        # Create error result if Jest output is missing
        if [[ ! -f "$chunk_output" ]]; then
            cat > "$chunk_output" << EOF
{
    "numTotalTests": 0,
    "numPassedTests": 0,
    "numFailedTests": 1,
    "numPendingTests": 0,
    "testResults": [],
    "success": false,
    "startTime": $((start_time * 1000)),
    "endTime": $((end_time * 1000)),
    "error": "Chunk execution failed with exit code $exit_code"
}
EOF
        fi
    fi
    
    return $exit_code
}

# Aggregate results from all chunks
aggregate_results() {
    local output_dir="$1"
    local final_output="$2"
    local verbose="$3"
    
    local total_tests=0 passed_tests=0 failed_tests=0 pending_tests=0
    local all_test_results=()
    local start_time=999999999999 end_time=0
    local overall_success=true
    
    log_info "Aggregating results from all chunks..."
    
    # Process each chunk result
    for result_file in "$output_dir"/results_chunk_*.json; do
        if [[ ! -f "$result_file" ]]; then
            continue
        fi
        
        # Extract metrics using simple grep/sed (avoiding jq dependency)
        local chunk_total chunk_passed chunk_failed chunk_pending
        chunk_total=$(grep -o '"numTotalTests":[0-9]*' "$result_file" | cut -d: -f2 || echo "0")
        chunk_passed=$(grep -o '"numPassedTests":[0-9]*' "$result_file" | cut -d: -f2 || echo "0")
        chunk_failed=$(grep -o '"numFailedTests":[0-9]*' "$result_file" | cut -d: -f2 || echo "0")
        chunk_pending=$(grep -o '"numPendingTests":[0-9]*' "$result_file" | cut -d: -f2 || echo "0")
        
        total_tests=$((total_tests + chunk_total))
        passed_tests=$((passed_tests + chunk_passed))
        failed_tests=$((failed_tests + chunk_failed))
        pending_tests=$((pending_tests + chunk_pending))
        
        # Check if this chunk had failures
        if [[ $chunk_failed -gt 0 ]]; then
            overall_success=false
        fi
        
        if [[ "$verbose" == "true" ]]; then
            log_info "Chunk $(basename "$result_file"): $chunk_total tests, $chunk_passed passed, $chunk_failed failed"
        fi
    done
    
    # Create aggregated result
    cat > "$final_output" << EOF
{
    "numTotalTests": $total_tests,
    "numPassedTests": $passed_tests,
    "numFailedTests": $failed_tests,
    "numPendingTests": $pending_tests,
    "success": $overall_success,
    "testResults": [],
    "aggregated": true,
    "timestamp": "$(date -Iseconds)"
}
EOF
    
    # Display summary
    log_info "Test execution completed:"
    log_info "  Total tests: $total_tests"
    log_info "  Passed: $passed_tests"
    log_info "  Failed: $failed_tests"
    log_info "  Pending: $pending_tests"
    
    if [[ $failed_tests -eq 0 ]]; then
        log_success "All tests passed!"
        return 0
    else
        log_error "$failed_tests test(s) failed"
        return 1
    fi
}

# Main parallel execution function
run_tests_parallel() {
    local test_files="$1"
    local concurrency="$2"
    local output_dir="$3"
    local timeout="$4"
    local verbose="$5"
    local dry_run="$6"
    
    if [[ -z "$test_files" ]]; then
        log_warn "No test files to run"
        return 0
    fi
    
    local file_count
    file_count=$(echo "$test_files" | wc -l)
    
    if [[ $file_count -eq 0 ]]; then
        log_warn "No test files provided"
        return 0
    fi
    
    log_info "Parallel test execution starting:"
    log_info "  Test files: $file_count"
    log_info "  Concurrency: $concurrency"
    log_info "  Output directory: $output_dir"
    log_info "  Timeout per chunk: ${timeout}s"
    
    if [[ "$dry_run" == "true" ]]; then
        log_info "DRY RUN - Would execute these tests:"
        echo "$test_files" | while IFS= read -r test_file; do
            echo "  - $test_file"
        done
        log_info "Would use $concurrency parallel processes"
        return 0
    fi
    
    # Create test chunks
    local chunk_count
    chunk_count=$(create_test_chunks "$test_files" "$concurrency" "$output_dir")
    
    if [[ $chunk_count -eq 0 ]]; then
        log_error "Failed to create test chunks"
        return 1
    fi
    
    log_info "Created $chunk_count test chunks"
    
    # Start parallel execution
    local pids=()
    local chunk_id=0
    local start_time end_time
    
    start_time=$(date +%s)
    
    for chunk_file in "$output_dir"/chunk_*.txt; do
        if [[ -f "$chunk_file" ]]; then
            # Run chunk in background
            run_test_chunk "$chunk_file" "$chunk_id" "$output_dir" "$timeout" "$verbose" &
            pids+=($!)
            
            if [[ "$verbose" == "true" ]]; then
                log_info "Started chunk $chunk_id (PID: $!)"
            fi
            
            ((chunk_id++))
        fi
    done
    
    # Wait for all chunks to complete
    local failed_chunks=0
    for i in "${!pids[@]}"; do
        local pid="${pids[$i]}"
        if ! wait "$pid"; then
            ((failed_chunks++))
            if [[ "$verbose" == "true" ]]; then
                log_warn "Chunk $i failed (PID: $pid)"
            fi
        fi
    done
    
    end_time=$(date +%s)
    local total_duration=$((end_time - start_time))
    
    log_info "All chunks completed in ${total_duration}s"
    
    if [[ $failed_chunks -gt 0 ]]; then
        log_warn "$failed_chunks chunk(s) had failures"
    fi
    
    # Aggregate and return results
    aggregate_results "$output_dir" "$output_dir/final_results.json" "$verbose"
}

# Clean up function
cleanup() {
    # Remove temporary chunk files but keep results
    if [[ -n "${TEMP_OUTPUT_DIR:-}" && -d "$TEMP_OUTPUT_DIR" ]]; then
        rm -f "$TEMP_OUTPUT_DIR"/chunk_*.txt
    fi
}

# Main execution function
main() {
    local concurrency="$DEFAULT_CONCURRENCY"
    local output_dir="./test-results"
    local timeout=300
    local verbose="false"
    local dry_run="false"
    local test_files=""
    
    # Parse command line arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -c|--concurrency)
                concurrency="$2"
                shift 2
                ;;
            -o|--output)
                output_dir="$2"
                shift 2
                ;;
            -t|--timeout)
                timeout="$2"
                shift 2
                ;;
            -v|--verbose)
                verbose="true"
                shift
                ;;
            -d|--dry-run)
                dry_run="true"
                shift
                ;;
            -h|--help)
                show_usage
                return 0
                ;;
            --version)
                show_version
                return 0
                ;;
            -*)
                log_error "Unknown option: $1"
                show_usage
                return 1
                ;;
            *)
                # Test file arguments
                if [[ -z "$test_files" ]]; then
                    test_files="$1"
                else
                    test_files="$test_files"$'\n'"$1"
                fi
                shift
                ;;
        esac
    done
    
    # Set up cleanup trap
    trap cleanup EXIT
    
    # If no test files provided as arguments, read from stdin
    if [[ -z "$test_files" ]]; then
        if [[ ! -t 0 ]]; then  # stdin is not a terminal
            test_files=$(cat)
        else
            log_error "No test files provided"
            show_usage
            return 1
        fi
    fi
    
    # Auto-detect concurrency if needed
    if [[ "$concurrency" == "auto" ]]; then
        concurrency=$(get_optimal_concurrency)
        if [[ "$verbose" == "true" ]]; then
            log_info "Auto-detected concurrency: $concurrency"
        fi
    fi
    
    # Validate concurrency is a number
    if ! [[ "$concurrency" =~ ^[0-9]+$ ]] || [[ $concurrency -lt 1 ]]; then
        log_error "Invalid concurrency value: $concurrency"
        return 1
    fi
    
    # Enable verbose logging if requested
    if [[ "$verbose" == "true" ]]; then
        set -x
    fi
    
    log_info "Starting $SCRIPT_NAME v$VERSION"
    
    # Validate environment (skip in dry-run mode)
    if [[ "$dry_run" != "true" ]]; then
        check_jest_available || return 1
    fi
    
    # Store output dir for cleanup
    TEMP_OUTPUT_DIR="$output_dir"
    
    # Run parallel tests
    run_tests_parallel "$test_files" "$concurrency" "$output_dir" "$timeout" "$verbose" "$dry_run"
}

# Script entry point
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi